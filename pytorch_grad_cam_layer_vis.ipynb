{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_grad-cam_layer_vis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_46vkF-KlVql",
        "6e2zjJN4lNau"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_46vkF-KlVql",
        "colab_type": "text"
      },
      "source": [
        "## Vrstvova vizualiz√°cia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWgy1vMIHCNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import copy\n",
        "from PIL import Image\n",
        "import matplotlib.cm as mpl_color_map\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models\n",
        "from torch.optim import Adam\n",
        "import cv2\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOt9jOsPu_Q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fp85gUXHeRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_np_output(np_arr):\n",
        "    \"\"\"\n",
        "        This is a (kind of) bandaid fix to streamline saving procedure.\n",
        "        It converts all the outputs to the same format which is 3xWxH\n",
        "        with using sucecssive if clauses.\n",
        "    Args:\n",
        "        im_as_arr (Numpy array): Matrix of shape 1xWxH or WxH or 3xWxH\n",
        "    \"\"\"\n",
        "    # Phase/Case 1: The np arr only has 2 dimensions\n",
        "    # Result: Add a dimension at the beginning\n",
        "    if len(np_arr.shape) == 2:\n",
        "        np_arr = np.expand_dims(np_arr, axis=0)\n",
        "    # Phase/Case 2: Np arr has only 1 channel (assuming first dim is channel)\n",
        "    # Result: Repeat first channel and convert 1xWxH to 3xWxH\n",
        "    if np_arr.shape[0] == 1:\n",
        "        np_arr = np.repeat(np_arr, 3, axis=0)\n",
        "    # Phase/Case 3: Np arr is of shape 3xWxH\n",
        "    # Result: Convert it to WxHx3 in order to make it saveable by PIL\n",
        "    if np_arr.shape[0] == 3:\n",
        "        np_arr = np_arr.transpose(1, 2, 0)\n",
        "    # Phase/Case 4: NP arr is normalized between 0-1\n",
        "    # Result: Multiply with 255 and change type to make it saveable by PIL\n",
        "    if np.max(np_arr) <= 1:\n",
        "        np_arr = (np_arr*255).astype(np.uint8)\n",
        "    return np_arr\n",
        "\n",
        "def save_image(im, path):\n",
        "    \"\"\"\n",
        "        Saves a numpy matrix or PIL image as an image\n",
        "    Args:\n",
        "        im_as_arr (Numpy array): Matrix of shape DxWxH\n",
        "        path (str): Path to the image\n",
        "    \"\"\"\n",
        "    if isinstance(im, (np.ndarray, np.generic)):\n",
        "        im = format_np_output(im)\n",
        "        im = Image.fromarray(im)\n",
        "    \n",
        "    im.save(path)\n",
        "\n",
        "def preprocess_image(pil_im, resize_im=True):\n",
        "    \"\"\"\n",
        "        Processes image for CNNs\n",
        "    Args:\n",
        "        PIL_img (PIL_img): Image to process\n",
        "        resize_im (bool): Resize to 224 or not\n",
        "    returns:\n",
        "        im_as_var (torch variable): Variable that contains processed float tensor\n",
        "    \"\"\"\n",
        "    # mean and std list for channels (Imagenet)\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    # Resize image\n",
        "    if resize_im:\n",
        "        pil_im.thumbnail((224, 224))\n",
        "    im_as_arr = np.float32(pil_im)\n",
        "    im_as_arr = im_as_arr.transpose(2, 0, 1)  # Convert array to D,W,H\n",
        "    # Normalize the channels\n",
        "    for channel, _ in enumerate(im_as_arr):\n",
        "        im_as_arr[channel] /= 255\n",
        "        im_as_arr[channel] -= mean[channel]\n",
        "        im_as_arr[channel] /= std[channel]\n",
        "    # Convert to float tensor\n",
        "    im_as_ten = torch.from_numpy(im_as_arr).float()\n",
        "    # Add one more channel to the beginning. Tensor shape = 1,3,224,224\n",
        "    im_as_ten.unsqueeze_(0)\n",
        "    # Convert to Pytorch variable\n",
        "    im_as_var = Variable(im_as_ten, requires_grad=True)\n",
        "    return im_as_var\n",
        "\n",
        "def recreate_image(im_as_var):\n",
        "    \"\"\"\n",
        "        Recreates images from a torch variable, sort of reverse preprocessing\n",
        "    Args:\n",
        "        im_as_var (torch variable): Image to recreate\n",
        "    returns:\n",
        "        recreated_im (numpy arr): Recreated image in array\n",
        "    \"\"\"\n",
        "    reverse_mean = [-0.485, -0.456, -0.406]\n",
        "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
        "    recreated_im = copy.copy(im_as_var.data.numpy()[0])\n",
        "    for c in range(3):\n",
        "        recreated_im[c] /= reverse_std[c]\n",
        "        recreated_im[c] -= reverse_mean[c]\n",
        "    recreated_im[recreated_im > 1] = 1\n",
        "    recreated_im[recreated_im < 0] = 0\n",
        "    recreated_im = np.round(recreated_im * 255)\n",
        "\n",
        "    recreated_im = np.uint8(recreated_im).transpose(1, 2, 0)\n",
        "    return recreated_im\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBR58hEeHr8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNLayerVisualization():\n",
        "    \"\"\"\n",
        "        Produces an image that minimizes the loss of a convolution\n",
        "        operation for a specific layer and filter\n",
        "    \"\"\"\n",
        "    def __init__(self, model, selected_layer, selected_filter):\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        self.selected_layer = selected_layer\n",
        "        self.selected_filter = selected_filter\n",
        "        self.conv_output = 0\n",
        "        # Create the folder to export images if not exists\n",
        "        if not os.path.exists('../generated'):\n",
        "            os.makedirs('../generated')\n",
        "\n",
        "    def hook_layer(self):\n",
        "        def hook_function(module, grad_in, grad_out):\n",
        "            # Gets the conv output of the selected filter (from selected layer)\n",
        "            self.conv_output = grad_out[0, self.selected_filter]\n",
        "        # Hook the selected layer\n",
        "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
        "\n",
        "    def visualise_layer_with_hooks(self):\n",
        "        # Hook the selected layer\n",
        "        self.hook_layer()\n",
        "        # Generate a random image\n",
        "        random_image = np.uint8(np.random.uniform(150, 180, (56, 56, 3)))\n",
        "        # Process image and return variable\n",
        "        processed_image = preprocess_image(random_image, False)\n",
        "        # Define optimizer for the image\n",
        "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
        "        for i in range(1, 31):\n",
        "            optimizer.zero_grad()\n",
        "            # Assign create image to a variable to move forward in the model\n",
        "            x = processed_image\n",
        "            for index, layer in enumerate(self.model):\n",
        "                # Forward pass layer by layer\n",
        "                # x is not used after this point because it is only needed to trigger\n",
        "                # the forward hook function\n",
        "                x = layer(x)\n",
        "                # Only need to forward until the selected layer is reached\n",
        "                if index == self.selected_layer:\n",
        "                    # (forward hook function triggered)\n",
        "                    break\n",
        "            # Loss function is the mean of the output of the selected layer/filter\n",
        "            # We try to minimize the mean of the output of that specific filter\n",
        "            loss = -torch.mean(self.conv_output)\n",
        "            print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
        "            # Backward\n",
        "            loss.backward()\n",
        "            # Update image\n",
        "            optimizer.step()\n",
        "            # Recreate image\n",
        "            self.created_image = recreate_image(processed_image)\n",
        "            # Save image\n",
        "            if i % 5 == 0:\n",
        "                print(\"saving image at iter \", i)\n",
        "                im_path = '/content/' + str(self.selected_layer) + \\\n",
        "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '_with_hooks.jpg'\n",
        "                save_image(self.created_image, im_path)\n",
        "\n",
        "    def visualise_layer_without_hooks(self,scale=1):\n",
        "        # Process image and return variable\n",
        "        # Generate a random image\n",
        "        sz = 256\n",
        "        random_image = np.uint8(np.random.uniform(150, 180, (sz, sz, 3)))\n",
        "        # Process image and return variable\n",
        "        processed_image = preprocess_image(random_image, False)\n",
        "        # Define optimizer for the image\n",
        "        for i in range(scale):\n",
        "          processed_image = preprocess_image(random_image, False)\n",
        "          optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
        "          for i in range(1, 20):\n",
        "              \n",
        "              optimizer.zero_grad()\n",
        "            # Assign create image to a variable to move forward in the model\n",
        "              x = processed_image\n",
        "              for index, layer in enumerate(self.model):\n",
        "                # Forward pass layer by layer\n",
        "                  x = layer(x)\n",
        "                  if index == self.selected_layer:\n",
        "                    # Only need to forward until the selected layer is reached\n",
        "                    # Now, x is the output of the selected layer\n",
        "                      break\n",
        "            # Here, we get the specific filter from the output of the convolution operation\n",
        "            # x is a tensor of shape 1x512x28x28.(For layer 17)\n",
        "            # So there are 512 unique filter outputs\n",
        "            # Following line selects a filter from 512 filters so self.conv_output will become\n",
        "            # a tensor of shape 28x28\n",
        "              self.conv_output = x[0, self.selected_filter]\n",
        "            # Loss function is the mean of the output of the selected layer/filter\n",
        "            # We try to minimize the mean of the output of that specific filter\n",
        "              loss = -torch.mean(self.conv_output)\n",
        "              ##print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
        "            # Backward\n",
        "              loss.backward()\n",
        "            # Update image\n",
        "              optimizer.step()\n",
        "            # Recreate image\n",
        "               #random_image = val_tfms.denorm(img_var.data.cpu().numpy()[0].transpose(1,2,0))\n",
        "          sz = int(1.2 * sz)  # calculate new image size\n",
        "          random_image = cv2.resize(random_image, (sz, sz), interpolation = cv2.INTER_CUBIC)\n",
        "          #random_image = cv2.blur(random_image,(5,5))\n",
        "        self.created_image = recreate_image(processed_image)\n",
        "            # Save image\n",
        "        \n",
        "        print(\"saving image\")\n",
        "        im_path = '/content/generated' + str(self.selected_layer) + \\\n",
        "            '_f' + str(self.selected_filter) + '_iter' + str(i) + '_features_new.jpg'\n",
        "        save_image(self.created_image, im_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jQJSZ-sIG0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_model = models.vgg16(pretrained=True).features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVmhJhN-HxIF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn_layer = 5\n",
        "filter_pos = 1\n",
        "for i in tqdm(range(5)):\n",
        "  layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)\n",
        "  layer_vis.visualise_layer_without_hooks(scale=2)\n",
        "  cnn_layer+=2\n",
        "#layer_vis.visualise_layer_with_hooks()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kncBcEKpmu-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo apt install imagemagick\n",
        "!convert -append /content/generated/*.jpg -append /content/layers.jpg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e2zjJN4lNau",
        "colab_type": "text"
      },
      "source": [
        "## GRAD-CAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkojnLwU9QLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/kazuto1011/grad-cam-pytorch.git\n",
        "!sudo apt install imagemagick"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV1l4JTEzPwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm /content/grad-cam-pytorch/results/*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2E-2c2LvuQw",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#%cd grad-cam-pytorch/\n",
        "image = \"photo.jpg\" #@param {type:\"string\"}\n",
        "model = \"vgg16\" #@param [\"vgg16\",\"alexnet\"]\n",
        "layer = 'features' #@param [\"features\", \"avgpool\", \"classifier\"]\n",
        "!python main.py demo1 -i /content/$image -a vgg16 -t $layer --cuda\n",
        "!convert -append /content/grad-cam-pytorch/results/*.png +append /content/visualization.png"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb42zYTYlCWp",
        "colab_type": "text"
      },
      "source": [
        "### Web kamera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMEtlfoPe5-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6x3gJ4T365i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}